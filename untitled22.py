# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vkXRfgwc7DVfMRECjhsrWlJdGven1PHN
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d sovitrath/diabetic-retinopathy-2015-data-colored-resized

import zipfile
zip_ref = zipfile.ZipFile('/content/diabetic-retinopathy-2015-data-colored-resized.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import tensorflow
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Flatten
from keras.applications.resnet import ResNet50

conv_base = ResNet50(
    weights='imagenet',
    include_top = False,
    input_shape=(224,224,3)
)

conv_base.summary()

model = Sequential()

model.add(conv_base)
model.add(Flatten())
model.add(Dense(256,activation='relu'))
model.add(Dense(1,activation='sigmoid'))
model.build(input_shape=(None,224, 224, 3))

model.summary()

conv_base.trainable = False

# generators
train_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/colored_images/colored_images',
    labels='inferred',
    label_mode = 'int',
    batch_size=32,
    image_size=(224,224)
)

validation_ds = keras.utils.image_dataset_from_directory(
    directory = '/content/colored_images/colored_images',
    labels='inferred',
    label_mode = 'int',
    batch_size=32,
    image_size=(224,224)
)

# Normalize
def process(image,label):
    image = tensorflow.cast(image/255. ,tensorflow.float32)
    return image,label

train_ds = train_ds.map(process)
validation_ds = validation_ds.map(process)

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

history = model.fit(train_ds,epochs=10,validation_data=validation_ds)

train_ds_1 = keras.utils.image_dataset_from_directory(
    directory = '/content/colored_images/colored_images',
    image_size = (224,224),
    batch_size = 32,
    validation_split = 0.2,
    subset ="training",
    seed =123,
    label_mode ='categorical'


    )

val_ds_1 = keras.utils.image_dataset_from_directory(
    directory = '/content/colored_images/colored_images',
    image_size = (224,224),
    batch_size = 32,
    validation_split = 0.2,
    subset ="validation",
    seed =123,
    label_mode ='categorical'


    )

# Normalize
def process(image,label):
    image = tensorflow.cast(image/255. ,tensorflow.float32)
    return image,label

train_ds_1 = train_ds_1.map(process)
validation_ds_1 = val_ds_1.map(process)

model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])

history = model.fit(train_ds_1,epochs=10,validation_data=validation_ds_1)

