{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45-b1v3nzkH0"
      },
      "outputs": [],
      "source": [
        "# Step 1: Mount Google Drive (if your data is in Google Drive)\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 3: Define paths to training and test data\n",
        "train_dir = '/content/train'  # Make sure this folder contains sub-folders per class\n",
        "test_dir = '/content/test'\n",
        "\n",
        "# Step 4: Image Data Generator for data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Step 5: Load training and testing data\n",
        "batch_size = 32\n",
        "img_size = (224, 224)  # Image size expected by ResNet50\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Step 6: Get class weights for handling class imbalance\n",
        "classes = train_generator.classes\n",
        "class_labels = list(train_generator.class_indices.values())\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(classes), y=classes)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"Class Weights: \", class_weights)\n",
        "\n",
        "# Step 7: Build the model using Transfer Learning (ResNet50)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom top layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Adding dropout to prevent overfitting\n",
        "predictions = Dense(5, activation='softmax')(x)  # 5 output classes\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 8: Train the model\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_generator,\n",
        "    class_weight=class_weights,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_steps=len(test_generator)\n",
        ")\n",
        "\n",
        "# Step 9: Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ]
    }
  ]
}